{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "439c0607-9be8-4b32-af97-e56caf756e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup completato. I percorsi delle tabelle Delta sono pronti.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from deltalake.writer import write_deltalake\n",
    "from deltalake import DeltaTable\n",
    "\n",
    "DATA_SOURCE_PATH : str = '../data/'\n",
    "DATA_PARZIALI_2025_DIR_PATH : str = os.path.join(DATA_SOURCE_PATH, 'Stazione_Parametro_AnnoMese')\n",
    "DATA_STORICI_DIR_PATH : str = os.path.join(DATA_SOURCE_PATH, 'storico_Anno_Stazione_Parametro')\n",
    "\n",
    "DATA_ANAGRAFICA_PARAMETRI_PATH : str = os.path.join(DATA_SOURCE_PATH,\"AnagrafeParametri.csv\")\n",
    "DATA_ANAGRAFICA_STAZIONI_PATH : str = os.path.join(DATA_SOURCE_PATH,\"AnagrafeStazioni.csv\")\n",
    "\n",
    "DELTA_LAKE_BASE_PATH : str = '../delta_tables/'\n",
    "DELTA_ANAGRAFICA_STAZIONI_PATH : str = os.path.join(DELTA_LAKE_BASE_PATH, 'anagrafica_stazioni_bronze')\n",
    "DELTA_ANAGRAFICA_PARAMETRI_PATH : str = os.path.join(DELTA_LAKE_BASE_PATH, 'anagrafica_parametri_bronze')\n",
    "DELTA_QUALITA_ARIA_PATH : str = os.path.join(DELTA_LAKE_BASE_PATH, 'qualita_aria_bronze')\n",
    "\n",
    "\n",
    "print(\"Setup completato. I percorsi delle tabelle Delta sono pronti.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "879f30e6-f8a3-485a-9ab9-c7818f5767e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Inizio processamento Anagrafe Stazioni ---\n",
      "Letto il file dell'anagrafica stazioni. Trovate 273 righe.\n",
      "\n",
      "Informazioni sul DataFrame originale:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 273 entries, 0 to 272\n",
      "Data columns (total 15 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Stazione   273 non-null    object \n",
      " 1   Cod_staz   273 non-null    object \n",
      " 2   COMUNE     273 non-null    object \n",
      " 3   INDIRIZZO  273 non-null    object \n",
      " 4   PROVINCIA  273 non-null    object \n",
      " 5   Altezza    250 non-null    float64\n",
      " 6   Id_Param   273 non-null    int64  \n",
      " 7   PARAMETRO  273 non-null    object \n",
      " 8   UM         273 non-null    object \n",
      " 9   Coord_X    273 non-null    float64\n",
      " 10  Coord_Y    273 non-null    float64\n",
      " 11  SR         273 non-null    int64  \n",
      " 12  LON_GEO    273 non-null    float64\n",
      " 13  LAT_GEO    273 non-null    float64\n",
      " 14  SR_GEO     273 non-null    int64  \n",
      "dtypes: float64(5), int64(3), object(7)\n",
      "memory usage: 32.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stazione</th>\n",
       "      <th>Cod_staz</th>\n",
       "      <th>COMUNE</th>\n",
       "      <th>INDIRIZZO</th>\n",
       "      <th>PROVINCIA</th>\n",
       "      <th>Altezza</th>\n",
       "      <th>Id_Param</th>\n",
       "      <th>PARAMETRO</th>\n",
       "      <th>UM</th>\n",
       "      <th>Coord_X</th>\n",
       "      <th>Coord_Y</th>\n",
       "      <th>SR</th>\n",
       "      <th>LON_GEO</th>\n",
       "      <th>LAT_GEO</th>\n",
       "      <th>SR_GEO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GIARDINI MARGHERITA</td>\n",
       "      <td>7.000.014</td>\n",
       "      <td>BOLOGNA</td>\n",
       "      <td>VIALE BOTTONELLI</td>\n",
       "      <td>BO</td>\n",
       "      <td>43.0</td>\n",
       "      <td>5</td>\n",
       "      <td>PM10</td>\n",
       "      <td>ug/m3</td>\n",
       "      <td>687199.0608</td>\n",
       "      <td>4.928180e+06</td>\n",
       "      <td>25832</td>\n",
       "      <td>11.354062</td>\n",
       "      <td>44.482671</td>\n",
       "      <td>4326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GIARDINI MARGHERITA</td>\n",
       "      <td>7.000.014</td>\n",
       "      <td>BOLOGNA</td>\n",
       "      <td>VIALE BOTTONELLI</td>\n",
       "      <td>BO</td>\n",
       "      <td>43.0</td>\n",
       "      <td>7</td>\n",
       "      <td>O3 (Ozono)</td>\n",
       "      <td>ug/m3</td>\n",
       "      <td>687199.0608</td>\n",
       "      <td>4.928180e+06</td>\n",
       "      <td>25832</td>\n",
       "      <td>11.354062</td>\n",
       "      <td>44.482671</td>\n",
       "      <td>4326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GIARDINI MARGHERITA</td>\n",
       "      <td>7.000.014</td>\n",
       "      <td>BOLOGNA</td>\n",
       "      <td>VIALE BOTTONELLI</td>\n",
       "      <td>BO</td>\n",
       "      <td>43.0</td>\n",
       "      <td>8</td>\n",
       "      <td>NO2 (Biossido di azoto)</td>\n",
       "      <td>ug/m3</td>\n",
       "      <td>687199.0608</td>\n",
       "      <td>4.928180e+06</td>\n",
       "      <td>25832</td>\n",
       "      <td>11.354062</td>\n",
       "      <td>44.482671</td>\n",
       "      <td>4326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GIARDINI MARGHERITA</td>\n",
       "      <td>7.000.014</td>\n",
       "      <td>BOLOGNA</td>\n",
       "      <td>VIALE BOTTONELLI</td>\n",
       "      <td>BO</td>\n",
       "      <td>43.0</td>\n",
       "      <td>111</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>ug/m3</td>\n",
       "      <td>687199.0608</td>\n",
       "      <td>4.928180e+06</td>\n",
       "      <td>25832</td>\n",
       "      <td>11.354062</td>\n",
       "      <td>44.482671</td>\n",
       "      <td>4326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PORTA SAN FELICE</td>\n",
       "      <td>7.000.015</td>\n",
       "      <td>BOLOGNA</td>\n",
       "      <td>PIAZZA DI PORTA SAN FELICE</td>\n",
       "      <td>BO</td>\n",
       "      <td>54.0</td>\n",
       "      <td>5</td>\n",
       "      <td>PM10</td>\n",
       "      <td>ug/m3</td>\n",
       "      <td>685037.0762</td>\n",
       "      <td>4.929940e+06</td>\n",
       "      <td>25832</td>\n",
       "      <td>11.327527</td>\n",
       "      <td>44.499060</td>\n",
       "      <td>4326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Stazione   Cod_staz   COMUNE                   INDIRIZZO  \\\n",
       "0  GIARDINI MARGHERITA  7.000.014  BOLOGNA            VIALE BOTTONELLI   \n",
       "1  GIARDINI MARGHERITA  7.000.014  BOLOGNA            VIALE BOTTONELLI   \n",
       "2  GIARDINI MARGHERITA  7.000.014  BOLOGNA            VIALE BOTTONELLI   \n",
       "3  GIARDINI MARGHERITA  7.000.014  BOLOGNA            VIALE BOTTONELLI   \n",
       "4     PORTA SAN FELICE  7.000.015  BOLOGNA  PIAZZA DI PORTA SAN FELICE   \n",
       "\n",
       "  PROVINCIA  Altezza  Id_Param                PARAMETRO     UM      Coord_X  \\\n",
       "0        BO     43.0         5                     PM10  ug/m3  687199.0608   \n",
       "1        BO     43.0         7               O3 (Ozono)  ug/m3  687199.0608   \n",
       "2        BO     43.0         8  NO2 (Biossido di azoto)  ug/m3  687199.0608   \n",
       "3        BO     43.0       111                    PM2.5  ug/m3  687199.0608   \n",
       "4        BO     54.0         5                     PM10  ug/m3  685037.0762   \n",
       "\n",
       "        Coord_Y     SR    LON_GEO    LAT_GEO  SR_GEO  \n",
       "0  4.928180e+06  25832  11.354062  44.482671    4326  \n",
       "1  4.928180e+06  25832  11.354062  44.482671    4326  \n",
       "2  4.928180e+06  25832  11.354062  44.482671    4326  \n",
       "3  4.928180e+06  25832  11.354062  44.482671    4326  \n",
       "4  4.929940e+06  25832  11.327527  44.499060    4326  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pulizia della colonna 'Cod_staz'...\n",
      "Pulizia completata con successo!\n",
      "Riempimento altezze vuote\n",
      "\n",
      "Informazioni sul DataFrame pulito (dopo la pulizia):\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 273 entries, 0 to 272\n",
      "Data columns (total 15 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Stazione   273 non-null    object \n",
      " 1   Cod_staz   273 non-null    int64  \n",
      " 2   COMUNE     273 non-null    object \n",
      " 3   INDIRIZZO  273 non-null    object \n",
      " 4   PROVINCIA  273 non-null    object \n",
      " 5   Altezza    273 non-null    float64\n",
      " 6   Id_Param   273 non-null    int64  \n",
      " 7   PARAMETRO  273 non-null    object \n",
      " 8   UM         273 non-null    object \n",
      " 9   Coord_X    273 non-null    float64\n",
      " 10  Coord_Y    273 non-null    float64\n",
      " 11  SR         273 non-null    int64  \n",
      " 12  LON_GEO    273 non-null    float64\n",
      " 13  LAT_GEO    273 non-null    float64\n",
      " 14  SR_GEO     273 non-null    int64  \n",
      "dtypes: float64(5), int64(4), object(6)\n",
      "memory usage: 32.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stazione</th>\n",
       "      <th>Cod_staz</th>\n",
       "      <th>COMUNE</th>\n",
       "      <th>INDIRIZZO</th>\n",
       "      <th>PROVINCIA</th>\n",
       "      <th>Altezza</th>\n",
       "      <th>Id_Param</th>\n",
       "      <th>PARAMETRO</th>\n",
       "      <th>UM</th>\n",
       "      <th>Coord_X</th>\n",
       "      <th>Coord_Y</th>\n",
       "      <th>SR</th>\n",
       "      <th>LON_GEO</th>\n",
       "      <th>LAT_GEO</th>\n",
       "      <th>SR_GEO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GIARDINI MARGHERITA</td>\n",
       "      <td>7000014</td>\n",
       "      <td>BOLOGNA</td>\n",
       "      <td>VIALE BOTTONELLI</td>\n",
       "      <td>BO</td>\n",
       "      <td>43.0</td>\n",
       "      <td>5</td>\n",
       "      <td>PM10</td>\n",
       "      <td>ug/m3</td>\n",
       "      <td>687199.0608</td>\n",
       "      <td>4.928180e+06</td>\n",
       "      <td>25832</td>\n",
       "      <td>11.354062</td>\n",
       "      <td>44.482671</td>\n",
       "      <td>4326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GIARDINI MARGHERITA</td>\n",
       "      <td>7000014</td>\n",
       "      <td>BOLOGNA</td>\n",
       "      <td>VIALE BOTTONELLI</td>\n",
       "      <td>BO</td>\n",
       "      <td>43.0</td>\n",
       "      <td>7</td>\n",
       "      <td>O3 (Ozono)</td>\n",
       "      <td>ug/m3</td>\n",
       "      <td>687199.0608</td>\n",
       "      <td>4.928180e+06</td>\n",
       "      <td>25832</td>\n",
       "      <td>11.354062</td>\n",
       "      <td>44.482671</td>\n",
       "      <td>4326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GIARDINI MARGHERITA</td>\n",
       "      <td>7000014</td>\n",
       "      <td>BOLOGNA</td>\n",
       "      <td>VIALE BOTTONELLI</td>\n",
       "      <td>BO</td>\n",
       "      <td>43.0</td>\n",
       "      <td>8</td>\n",
       "      <td>NO2 (Biossido di azoto)</td>\n",
       "      <td>ug/m3</td>\n",
       "      <td>687199.0608</td>\n",
       "      <td>4.928180e+06</td>\n",
       "      <td>25832</td>\n",
       "      <td>11.354062</td>\n",
       "      <td>44.482671</td>\n",
       "      <td>4326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GIARDINI MARGHERITA</td>\n",
       "      <td>7000014</td>\n",
       "      <td>BOLOGNA</td>\n",
       "      <td>VIALE BOTTONELLI</td>\n",
       "      <td>BO</td>\n",
       "      <td>43.0</td>\n",
       "      <td>111</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>ug/m3</td>\n",
       "      <td>687199.0608</td>\n",
       "      <td>4.928180e+06</td>\n",
       "      <td>25832</td>\n",
       "      <td>11.354062</td>\n",
       "      <td>44.482671</td>\n",
       "      <td>4326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PORTA SAN FELICE</td>\n",
       "      <td>7000015</td>\n",
       "      <td>BOLOGNA</td>\n",
       "      <td>PIAZZA DI PORTA SAN FELICE</td>\n",
       "      <td>BO</td>\n",
       "      <td>54.0</td>\n",
       "      <td>5</td>\n",
       "      <td>PM10</td>\n",
       "      <td>ug/m3</td>\n",
       "      <td>685037.0762</td>\n",
       "      <td>4.929940e+06</td>\n",
       "      <td>25832</td>\n",
       "      <td>11.327527</td>\n",
       "      <td>44.499060</td>\n",
       "      <td>4326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Stazione  Cod_staz   COMUNE                   INDIRIZZO  \\\n",
       "0  GIARDINI MARGHERITA   7000014  BOLOGNA            VIALE BOTTONELLI   \n",
       "1  GIARDINI MARGHERITA   7000014  BOLOGNA            VIALE BOTTONELLI   \n",
       "2  GIARDINI MARGHERITA   7000014  BOLOGNA            VIALE BOTTONELLI   \n",
       "3  GIARDINI MARGHERITA   7000014  BOLOGNA            VIALE BOTTONELLI   \n",
       "4     PORTA SAN FELICE   7000015  BOLOGNA  PIAZZA DI PORTA SAN FELICE   \n",
       "\n",
       "  PROVINCIA  Altezza  Id_Param                PARAMETRO     UM      Coord_X  \\\n",
       "0        BO     43.0         5                     PM10  ug/m3  687199.0608   \n",
       "1        BO     43.0         7               O3 (Ozono)  ug/m3  687199.0608   \n",
       "2        BO     43.0         8  NO2 (Biossido di azoto)  ug/m3  687199.0608   \n",
       "3        BO     43.0       111                    PM2.5  ug/m3  687199.0608   \n",
       "4        BO     54.0         5                     PM10  ug/m3  685037.0762   \n",
       "\n",
       "        Coord_Y     SR    LON_GEO    LAT_GEO  SR_GEO  \n",
       "0  4.928180e+06  25832  11.354062  44.482671    4326  \n",
       "1  4.928180e+06  25832  11.354062  44.482671    4326  \n",
       "2  4.928180e+06  25832  11.354062  44.482671    4326  \n",
       "3  4.928180e+06  25832  11.354062  44.482671    4326  \n",
       "4  4.929940e+06  25832  11.327527  44.499060    4326  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scrittura nella tabella Delta: ../delta_tables/anagrafica_stazioni_bronze\n",
      "Tabella Anagrafe Stazioni scritta con successo in formato Delta Lake.\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Inizio processamento Anagrafe Stazioni ---\")\n",
    "try:\n",
    "    stazioni_dataframe = pd.read_csv(DATA_ANAGRAFICA_STAZIONI_PATH)\n",
    "    print(f\"Letto il file dell'anagrafica stazioni. Trovate {len(stazioni_dataframe)} righe.\")\n",
    "    print(\"\\nInformazioni sul DataFrame originale:\")\n",
    "    stazioni_dataframe.info()\n",
    "    display(stazioni_dataframe.head())\n",
    "\n",
    "\n",
    "\n",
    "    print(\"\\nPulizia della colonna 'Cod_staz'...\")\n",
    "    \n",
    "    #Rimuoviamo i punti '.' dalla stringa\n",
    "    stazioni_dataframe['Cod_staz'] = stazioni_dataframe['Cod_staz'].astype(str).str.replace('.', '', regex=False)\n",
    "    \n",
    "    #Convertiamo la colonna pulita in un tipo numerico (intero)\n",
    "    stazioni_dataframe['Cod_staz'] = pd.to_numeric(stazioni_dataframe['Cod_staz'], errors='coerce')\n",
    "    \n",
    "    #Rimuoviamo eventuali righe dove la conversione è fallita\n",
    "    stazioni_dataframe.dropna(subset=['Cod_staz'], inplace=True)\n",
    "    \n",
    "    #Convertiamo in un intero non-nullo per pulizia finale\n",
    "    stazioni_dataframe['Cod_staz'] = stazioni_dataframe['Cod_staz'].astype(int)\n",
    "    \n",
    "    print(\"Pulizia completata con successo!\")\n",
    "\n",
    "    print(\"Riempimento altezze vuote\")\n",
    "    stazioni_dataframe[\"Altezza\"] = stazioni_dataframe[\"Altezza\"].fillna(0)\n",
    "\n",
    "    \n",
    "    # Visualizziamo i tipi di dato DOPO la pulizia per verificare\n",
    "    print(\"\\nInformazioni sul DataFrame pulito (dopo la pulizia):\")\n",
    "    stazioni_dataframe.info()\n",
    "    display(stazioni_dataframe.head())\n",
    "\n",
    "    print(f\"\\nScrittura nella tabella Delta: {DELTA_ANAGRAFICA_STAZIONI_PATH}\")\n",
    "    write_deltalake(DELTA_ANAGRAFICA_STAZIONI_PATH, stazioni_dataframe, mode=\"overwrite\")\n",
    "    print(\"Tabella Anagrafe Stazioni scritta con successo in formato Delta Lake.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERRORE: File non trovato in '{DATA_ANAGRAFICA_STAZIONI_PATH}'. Assicurati che il file esista e il percorso sia corretto.\")\n",
    "except Exception as e:\n",
    "    print(f\"Si è verificato un errore: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e841e697-ccd0-4d0b-9576-f696e85d0d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Inizio processamento Anagrafe Parametri ---\n",
      "Letto il file dell'anagrafica parametri. Trovate 21 righe.\n",
      "\n",
      "Informazioni sul DataFrame originale:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21 entries, 0 to 20\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   IdParametro  21 non-null     int64 \n",
      " 1   PARAMETRO    21 non-null     object\n",
      " 2   UM           21 non-null     object\n",
      " 3   Tmed (min)   21 non-null     int64 \n",
      " 4   NOTE         21 non-null     object\n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 972.0+ bytes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IdParametro</th>\n",
       "      <th>PARAMETRO</th>\n",
       "      <th>UM</th>\n",
       "      <th>Tmed (min)</th>\n",
       "      <th>NOTE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>SO2 (Biossido di zolfo)</td>\n",
       "      <td>ug/m3</td>\n",
       "      <td>60</td>\n",
       "      <td>Valori medi orari, l'ora riportata e' quella d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>PM10</td>\n",
       "      <td>ug/m3</td>\n",
       "      <td>1440</td>\n",
       "      <td>Valori medi giornalieri, il giorno riportato e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>O3 (Ozono)</td>\n",
       "      <td>ug/m3</td>\n",
       "      <td>60</td>\n",
       "      <td>Valori medi orari, l'ora riportata e' quella d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>NO2 (Biossido di azoto)</td>\n",
       "      <td>ug/m3</td>\n",
       "      <td>60</td>\n",
       "      <td>Valori medi orari, l'ora riportata e' quella d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>NOX (Ossidi di azoto)</td>\n",
       "      <td>ug/m3</td>\n",
       "      <td>60</td>\n",
       "      <td>Valori medi orari, l'ora riportata e' quella d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   IdParametro                PARAMETRO     UM  Tmed (min)  \\\n",
       "0            1  SO2 (Biossido di zolfo)  ug/m3          60   \n",
       "1            5                     PM10  ug/m3        1440   \n",
       "2            7               O3 (Ozono)  ug/m3          60   \n",
       "3            8  NO2 (Biossido di azoto)  ug/m3          60   \n",
       "4            9    NOX (Ossidi di azoto)  ug/m3          60   \n",
       "\n",
       "                                                NOTE  \n",
       "0  Valori medi orari, l'ora riportata e' quella d...  \n",
       "1  Valori medi giornalieri, il giorno riportato e...  \n",
       "2  Valori medi orari, l'ora riportata e' quella d...  \n",
       "3  Valori medi orari, l'ora riportata e' quella d...  \n",
       "4  Valori medi orari, l'ora riportata e' quella d...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scrittura nella tabella Delta: ../delta_tables/anagrafica_parametri_bronze\n",
      "Tabella Anagrafe Parametri scritta con successo in formato Delta Lake.\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Inizio processamento Anagrafe Parametri ---\")\n",
    "try:\n",
    "    parametri_dataframe = pd.read_csv(DATA_ANAGRAFICA_PARAMETRI_PATH)\n",
    "    print(f\"Letto il file dell'anagrafica parametri. Trovate {len(parametri_dataframe)} righe.\")\n",
    "    print(\"\\nInformazioni sul DataFrame originale:\")\n",
    "    parametri_dataframe.info()\n",
    "    display(parametri_dataframe.head())\n",
    "\n",
    "    print(f\"\\nScrittura nella tabella Delta: {DELTA_ANAGRAFICA_PARAMETRI_PATH}\")\n",
    "    write_deltalake(DELTA_ANAGRAFICA_PARAMETRI_PATH, parametri_dataframe, mode=\"overwrite\")\n",
    "    print(\"Tabella Anagrafe Parametri scritta con successo in formato Delta Lake.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERRORE: File non trovato in '{DELTA_ANAGRAFICA_PARAMETRI_PATH}'. Assicurati che il file esista e il percorso sia corretto.\")\n",
    "except Exception as e:\n",
    "    print(f\"Si è verificato un errore: {e}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "05e0c748-8e77-46b3-812b-9b3cd65558d5",
   "metadata": {},
   "source": [
    "La tabella principale avrà uno schema che unifica i dati di entrambe le tabelle di dati eliminando le ridondanze:\n",
    "•\tCOD_STAZ\n",
    "•\tID_PARAM\n",
    "•\tDATA_INIZIO\n",
    "•\tDATA_FINE\n",
    "•\tVALORE\n",
    "•\tVALIDAZIONE\n",
    "\n",
    "I dati parziali sono nel formato\n",
    "•    COD_STAZ\n",
    "•    ID_PARAM\n",
    "•    DATA_FINE\n",
    "•    VALORE\n",
    "•    VALIDAZIONE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3740d95f-44d8-4b06-8739-261f032e2158",
   "metadata": {},
   "source": [
    "# PROCESSAMENTO PARZIALI 2025\n",
    "## 1) Unione dei vari csv in un unico dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a25880ff-1be6-420c-9e55-f180e58692f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Inizio processamento Parziali 2025 ---\n",
      "Caricamento di tutti i csv in un unico df...\n",
      "Trovati 226 file CSV:\n",
      "Caricamento completato con successo! \n",
      "Unione DataFrame in corso...\n",
      "DataFrame unificato creato con successo.\n",
      "Dimensioni totali: (685177, 5)\n",
      "        COD_STAZ  ID_PARAM         DATA_FINE  VALORE VALIDAZIONE\n",
      "0       10000002         7  01/01/2025 01:00     2.0           S\n",
      "1       10000002         7  01/01/2025 02:00     2.0           S\n",
      "2       10000002         7  01/01/2025 03:00     2.0           S\n",
      "3       10000002         7  01/01/2025 04:00     2.0           S\n",
      "4       10000002         7  01/01/2025 05:00     1.0           S\n",
      "...          ...       ...               ...     ...         ...\n",
      "685172   7000015        38  30/06/2025 20:00     3.0           S\n",
      "685173   7000015        38  30/06/2025 21:00     1.0           S\n",
      "685174   7000015        38  30/06/2025 22:00     1.0           S\n",
      "685175   7000015        38  30/06/2025 23:00     3.0           S\n",
      "685176   7000015        38  01/07/2025 00:00     3.0           S\n",
      "\n",
      "[685177 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Inizio processamento Parziali 2025 ---\")\n",
    "\n",
    "parziali_df_list : list = []\n",
    "formato_data : str = '%d/%m/%Y %H:%M'\n",
    "\n",
    "try:\n",
    "    print(\"Caricamento di tutti i csv in un unico df...\")\n",
    "    pattern = os.path.join(DATA_PARZIALI_2025_DIR_PATH, '*.csv')\n",
    "    lista_file_csv = glob.glob(pattern)\n",
    "    print(f\"Trovati {len(lista_file_csv)} file CSV:\")\n",
    "    for file_csv in lista_file_csv:\n",
    "        #print(f\"proceso il file {os.path.basename(file_csv)}\")\n",
    "        df_temp = pd.read_csv(file_csv)\n",
    "        parziali_df_list.append(df_temp)\n",
    "    \n",
    "    print(\"Caricamento completato con successo! \")\n",
    "\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERRORE: File non trovato in '{DELTA_ANAGRAFICA_PARAMETRI_PATH}'. Assicurati che il file esista e il percorso sia corretto.\")\n",
    "except Exception as e:\n",
    "    print(f\"Si è verificato un errore: {e}\")\n",
    "\n",
    "if parziali_df_list: \n",
    "    print(\"Unione DataFrame in corso...\")\n",
    "    corrente_df = pd.concat(parziali_df_list, ignore_index=True)\n",
    "    print(\"DataFrame unificato creato con successo.\")\n",
    "    print(\"Dimensioni totali:\", corrente_df.shape)\n",
    "else:\n",
    "    print(\"Nessun DataFrame da unire.\")\n",
    "    corrente_df = pd.DataFrame()\n",
    "\n",
    "print(corrente_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b93bc8-7a43-49dd-a70c-ae76a025a774",
   "metadata": {},
   "source": [
    "## 2) Pulizia dei dati e riordinamento della colonna\n",
    "Dato che i parametri 5 e 111 sono con misurazione giornaliera mentre gli altri con misurazione oraria creo una maschera per inserire la data inizio ogni giorno per 5, 111 e "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da8da879-6661-434b-968e-7a22c4b43350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pulizia dei dati nel dataframe\n",
      "Inserimento colonna DATA_INIZIO...\n",
      "Inserita colonna DATA_INIZIO\n",
      "Rimossi 0 record con date o valori non validi.\n",
      "Colonne riordinate.\n",
      "        COD_STAZ  ID_PARAM         DATA_INIZIO           DATA_FINE  VALORE  \\\n",
      "0       10000002         7 2025-01-01 00:00:00 2025-01-01 01:00:00     2.0   \n",
      "1       10000002         7 2025-01-01 01:00:00 2025-01-01 02:00:00     2.0   \n",
      "2       10000002         7 2025-01-01 02:00:00 2025-01-01 03:00:00     2.0   \n",
      "3       10000002         7 2025-01-01 03:00:00 2025-01-01 04:00:00     2.0   \n",
      "4       10000002         7 2025-01-01 04:00:00 2025-01-01 05:00:00     1.0   \n",
      "...          ...       ...                 ...                 ...     ...   \n",
      "685172   7000015        38 2025-06-30 19:00:00 2025-06-30 20:00:00     3.0   \n",
      "685173   7000015        38 2025-06-30 20:00:00 2025-06-30 21:00:00     1.0   \n",
      "685174   7000015        38 2025-06-30 21:00:00 2025-06-30 22:00:00     1.0   \n",
      "685175   7000015        38 2025-06-30 22:00:00 2025-06-30 23:00:00     3.0   \n",
      "685176   7000015        38 2025-06-30 23:00:00 2025-07-01 00:00:00     3.0   \n",
      "\n",
      "       VALIDAZIONE  \n",
      "0                S  \n",
      "1                S  \n",
      "2                S  \n",
      "3                S  \n",
      "4                S  \n",
      "...            ...  \n",
      "685172           S  \n",
      "685173           S  \n",
      "685174           S  \n",
      "685175           S  \n",
      "685176           S  \n",
      "\n",
      "[685177 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "daily_check : list = [5, 111]\n",
    "mask_giorni = corrente_df['ID_PARAM'].isin([5, 111])\n",
    "mask_ore = ~mask_giorni\n",
    "\n",
    "\n",
    "if not corrente_df.empty:\n",
    "    print(\"Pulizia dei dati nel dataframe\")\n",
    "    print(\"Inserimento colonna DATA_INIZIO...\")\n",
    "\n",
    "    corrente_df['DATA_FINE'] = pd.to_datetime(corrente_df['DATA_FINE'], format=formato_data)\n",
    "    corrente_df['DATA_INIZIO'] = pd.NaT\n",
    "    corrente_df.loc[mask_giorni, 'DATA_INIZIO'] = corrente_df['DATA_FINE'] - pd.DateOffset(days=1)\n",
    "    corrente_df.loc[mask_ore, 'DATA_INIZIO'] = corrente_df['DATA_FINE'] - pd.DateOffset(hours=1)\n",
    "    \n",
    "    \n",
    "    print(\"Inserita colonna DATA_INIZIO\")\n",
    "\n",
    "    corrente_df['VALORE'] = corrente_df['VALORE'].astype(str).str.replace(',', '.', regex=False)\n",
    "    corrente_df['VALORE'] = pd.to_numeric(corrente_df['VALORE'], errors='coerce')\n",
    "    \n",
    "    rows_before = len(corrente_df)\n",
    "    corrente_df.dropna(subset=['DATA_FINE', 'VALORE'], inplace=True)\n",
    "    rows_after = len(corrente_df)\n",
    "    print(f\"Rimossi {rows_before - rows_after} record con date o valori non validi.\")\n",
    "    \n",
    "    colonne_esistenti = list(corrente_df.columns)\n",
    "    colonne_esistenti.remove('DATA_INIZIO') \n",
    "    \n",
    "    colonne_esistenti.insert(2, 'DATA_INIZIO')\n",
    "    corrente_df = corrente_df[colonne_esistenti]\n",
    "    print(\"Colonne riordinate.\")\n",
    "    print(corrente_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c85e5e-4f43-4293-bd7e-902362c8b836",
   "metadata": {},
   "source": [
    "# PROCESSAMENTO DATI STORICI\n",
    "## 3) Unione dei vari file CSV storici in un unico DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc46e942-88a5-4bf8-9965-aac6aaa8fd7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Inizio processamento Dati Storici ---\n",
      "Trovati 3386 file CSV storici da processare.\n",
      "Inizio a unire i dataframe e processare i dati\n",
      "5% completato\n",
      "10% completato\n",
      "15% completato\n",
      "20% completato\n",
      "25% completato\n",
      "30% completato\n",
      "35% completato\n",
      "40% completato\n",
      "45% completato\n",
      "50% completato\n",
      "55% completato\n",
      "60% completato\n",
      "65% completato\n",
      "70% completato\n",
      "75% completato\n",
      "80% completato\n",
      "85% completato\n",
      "90% completato\n",
      "95% completato\n",
      "100% completato\n",
      "Terminato processamento dei dati\n",
      "\n",
      "Unione dei DataFrame storici in corso...\n",
      "DataFrame storico unificato creato con successo.\n",
      "Dimensioni totali dati storici: (20010821, 6)\n",
      "\n",
      "Anteprima del DataFrame storico pulito e armonizzato:\n",
      "          COD_STAZ  ID_PARAM         DATA_INIZIO           DATA_FINE  VALORE  \\\n",
      "0          7000002         5 2020-01-01 00:00:00 2020-01-02 00:00:00    39.0   \n",
      "1          7000002         5 2020-01-02 00:00:00 2020-01-03 00:00:00    49.0   \n",
      "2          7000002         5 2020-01-03 00:00:00 2020-01-04 00:00:00    44.0   \n",
      "3          7000002         5 2020-01-04 00:00:00 2020-01-05 00:00:00    27.0   \n",
      "4          7000002         5 2020-01-05 00:00:00 2020-01-06 00:00:00    28.0   \n",
      "...            ...       ...                 ...                 ...     ...   \n",
      "20010816   3000001         8 2013-12-31 19:00:00 2013-12-31 20:00:00    24.0   \n",
      "20010817   3000001         8 2013-12-31 20:00:00 2013-12-31 21:00:00    23.0   \n",
      "20010818   3000001         8 2013-12-31 21:00:00 2013-12-31 22:00:00    21.0   \n",
      "20010819   3000001         8 2013-12-31 22:00:00 2013-12-31 23:00:00    19.0   \n",
      "20010820   3000001         8 2013-12-31 23:00:00 2014-01-01 00:00:00    17.0   \n",
      "\n",
      "         VALIDAZIONE  \n",
      "0                  S  \n",
      "1                  S  \n",
      "2                  S  \n",
      "3                  S  \n",
      "4                  S  \n",
      "...              ...  \n",
      "20010816           S  \n",
      "20010817           S  \n",
      "20010818           S  \n",
      "20010819           S  \n",
      "20010820           S  \n",
      "\n",
      "[20010821 rows x 6 columns]\n",
      "\n",
      "Verifica tipi di dato (dtypes):\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20010821 entries, 0 to 20010820\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Dtype         \n",
      "---  ------       -----         \n",
      " 0   COD_STAZ     int64         \n",
      " 1   ID_PARAM     int64         \n",
      " 2   DATA_INIZIO  datetime64[ns]\n",
      " 3   DATA_FINE    datetime64[ns]\n",
      " 4   VALORE       float64       \n",
      " 5   VALIDAZIONE  object        \n",
      "dtypes: datetime64[ns](2), float64(1), int64(2), object(1)\n",
      "memory usage: 916.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Inizio processamento Dati Storici ---\")\n",
    "\n",
    "# Lista per accumulare i DataFrame storici\n",
    "storico_df_list = []\n",
    "\n",
    "# Definiamo il formato data atteso per i file storici, come per quelli correnti\n",
    "formato_data_storico = '%d/%m/%Y %H'\n",
    "\n",
    "# Trova tutti i file CSV nella directory dei dati storici\n",
    "pattern_storici = os.path.join(DATA_STORICI_DIR_PATH, '*.csv')\n",
    "lista_file_storici = glob.glob(pattern_storici)\n",
    "print(f\"Trovati {len(lista_file_storici)} file CSV storici da processare.\")\n",
    "\n",
    "perc_notifica = 5\n",
    "counter = 0 \n",
    "percentage_base = int(perc_notifica * len(lista_file_storici) / 100)\n",
    "\n",
    "# Itera su ogni file storico per caricarlo e armonizzarlo\n",
    "print(\"Inizio a unire i dataframe e processare i dati\")\n",
    "for index, file_csv in enumerate(lista_file_storici):\n",
    "    try:\n",
    "        # Leggiamo il CSV usando i parametri corretti per dati ben formattati.\n",
    "        # Rimuoviamo sep e encoding, mantenendo low_memory=False per sicurezza sui tipi.\n",
    "        df_temp_storico = pd.read_csv(file_csv, low_memory=False)\n",
    "        \n",
    "        # --- LOGICA DI PULIZIA E ARMONIZZAZIONE ---\n",
    "        if (index % percentage_base == 0 and index != 0):\n",
    "            print(f\"{perc_notifica*(counter+1)}% completato\")\n",
    "            counter += 1\n",
    "            \n",
    "        # 1. GESTIONE DATE: Convertiamo subito le colonne data usando il formato corretto.\n",
    "        df_temp_storico['DATA_INIZIO'] = pd.to_datetime(df_temp_storico['DATA_INIZIO'], format=formato_data_storico, errors='coerce')\n",
    "        df_temp_storico['DATA_FINE'] = pd.to_datetime(df_temp_storico['DATA_FINE'], format=formato_data_storico, errors='coerce')\n",
    "\n",
    "        # 2. GESTIONE VALORE NUMERICO: La logica rimane la stessa per sicurezza\n",
    "        df_temp_storico['VALORE'] = pd.to_numeric(df_temp_storico['VALORE'], errors='coerce')\n",
    "        \n",
    "        # 3. GESTIONE COLONNE EXTRA/MANCANTI\n",
    "        df_temp_storico.drop(columns=['UM'], inplace=True)\n",
    "        df_temp_storico['VALIDAZIONE'] = 'S'\n",
    "        \n",
    "        # Aggiungiamo il DataFrame pulito e armonizzato alla lista\n",
    "        storico_df_list.append(df_temp_storico)\n",
    "        \n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Attenzione: Errore durante l'elaborazione del file {os.path.basename(file_csv)}: {e}\")\n",
    "\n",
    "print(\"Terminato processamento dei dati\")\n",
    "# Uniamo tutti i DataFrame storici in uno solo\n",
    "if storico_df_list:\n",
    "    print(\"\\nUnione dei DataFrame storici in corso...\")\n",
    "    storico_df = pd.concat(storico_df_list, ignore_index=True)\n",
    "    print(\"DataFrame storico unificato creato con successo.\")\n",
    "    print(\"Dimensioni totali dati storici:\", storico_df.shape)\n",
    "else:\n",
    "    print(\"Nessun DataFrame storico da unire.\")\n",
    "    storico_df = pd.DataFrame()\n",
    "\n",
    "# Mostriamo un'anteprima del DataFrame storico armonizzato per verifica\n",
    "if not storico_df.empty:\n",
    "    print(\"\\nAnteprima del DataFrame storico pulito e armonizzato:\")\n",
    "    print(storico_df)\n",
    "    print(\"\\nVerifica tipi di dato (dtypes):\")\n",
    "    print(storico_df.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88869c16-c203-4977-b83d-958daf1dacf3",
   "metadata": {},
   "source": [
    "# UNIONE FINALE E SCRITTURA SU DELTA LAKE\n",
    "## 4) Unione dei dati correnti e storici, pulizia finale e scrittura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff86f65f-2f0f-4875-8300-960f1fc49a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Inizio Unione Finale e Scrittura ---\n",
      "Aggiunto DataFrame 'corrente_df' con 685177 righe.\n",
      "Aggiunto DataFrame 'storico_df' con 20010821 righe.\n",
      "\n",
      "Unione di 2 DataFrame(s) principali...\n",
      "DataFrame finale creato con 20695998 righe.\n",
      "Esecuzione pulizia finale su tutto il dataset...\n"
     ]
    }
   ],
   "source": [
    "# Cella 11 (Codice) - Unione Finale e Scrittura (con fix per l'indice extra)\n",
    "\n",
    "print(\"--- Inizio Unione Finale e Scrittura ---\")\n",
    "\n",
    "# ... (la parte iniziale di unione dei DataFrame rimane identica) ...\n",
    "dataframes_to_concat = []\n",
    "if 'corrente_df' in locals() and not corrente_df.empty:\n",
    "    dataframes_to_concat.append(corrente_df)\n",
    "    print(f\"Aggiunto DataFrame 'corrente_df' con {len(corrente_df)} righe.\")\n",
    "if 'storico_df' in locals() and not storico_df.empty:\n",
    "    dataframes_to_concat.append(storico_df)\n",
    "    print(f\"Aggiunto DataFrame 'storico_df' con {len(storico_df)} righe.\")\n",
    "\n",
    "if dataframes_to_concat:\n",
    "    print(f\"\\nUnione di {len(dataframes_to_concat)} DataFrame(s) principali...\")\n",
    "    final_df = pd.concat(dataframes_to_concat, ignore_index=True)\n",
    "    print(f\"DataFrame finale creato con {len(final_df)} righe.\")\n",
    "\n",
    "    # --- PULIZIA FINALE SUL DATAFRAME UNIFICATO ---\n",
    "    print(\"Esecuzione pulizia finale su tutto il dataset...\")\n",
    "    rows_before = len(final_df)\n",
    "    final_df.dropna(subset=['DATA_FINE', 'VALORE', 'COD_STAZ'], inplace=True)\n",
    "    rows_after = len(final_df)\n",
    "    print(f\"Rimossi {rows_before - rows_after} record con valori nulli in colonne critiche.\")\n",
    "    \n",
    "    # --- MODIFICA CHIAVE: RESETTIAMO L'INDICE PRIMA DI SALVARE ---\n",
    "    # Il parametro drop=True è FONDAMENTALE: butta via il vecchio indice invece di\n",
    "    # trasformarlo in una nuova colonna. Questo risolve il problema di '__index_level_0__'.\n",
    "    final_df.reset_index(drop=True, inplace=True)\n",
    "    print(\"Indice del DataFrame finale resettato per evitare colonne extra.\")\n",
    "    \n",
    "    # --- Assicuriamoci che l'ordine delle colonne sia esattamente quello target.\n",
    "    colonne_finali = ['COD_STAZ', 'ID_PARAM', 'DATA_INIZIO', 'DATA_FINE', 'VALORE', 'VALIDAZIONE']\n",
    "    final_df = final_df[colonne_finali]\n",
    "    print(\"Colonne riordinate secondo lo schema target.\")\n",
    "    \n",
    "    # --- SCRITTURA NELLA TABELLA DELTA LAKE (con la chiamata corretta) ---\n",
    "    print(f\"\\nScrittura di {len(final_df)} righe nella tabella Delta: {DELTA_QUALITA_ARIA_PATH}\")\n",
    "    write_deltalake(\n",
    "        DELTA_QUALITA_ARIA_PATH,\n",
    "        final_df,\n",
    "        mode='overwrite' \n",
    "    )\n",
    "    \n",
    "    print(\"SCRITTURA COMPLETATA. La tabella 'qualita_aria_bronze' è stata creata/aggiornata.\")\n",
    "else:\n",
    "    print(\"Nessun dato da scrivere nella tabella Delta.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a802fa88-13bd-481c-9374-26d30f01f20c",
   "metadata": {},
   "source": [
    "# Verifica finale  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233c3152-0256-415d-8595-478f3e319c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Verifica Finale della Tabella 'qualita_aria_bronze' ---\")\n",
    "\n",
    "try:\n",
    "    # Carichiamo la tabella Delta appena scritta per ispezionarla\n",
    "    bronze_table_df = DeltaTable(DELTA_QUALITA_ARIA_PATH).to_pandas()\n",
    "\n",
    "    print(f\"\\nLa tabella contiene {len(bronze_table_df)} righe.\")\n",
    "    print(\"\\n> Prime 5 righe della tabella:\")\n",
    "    display(bronze_table_df.head())\n",
    "\n",
    "    print(\"\\n> Schema (.info()) della tabella:\")\n",
    "    bronze_table_df.info()\n",
    "\n",
    "    # Controllo di coerenza finale per la massima sicurezza\n",
    "    colonne_attese = ['COD_STAZ', 'ID_PARAM', 'DATA_INIZIO', 'DATA_FINE', 'VALORE', 'VALIDAZIONE']\n",
    "    if bronze_table_df.columns.tolist() == colonne_attese:\n",
    "        print(\"\\n[SUCCESS] Verifica superata: Lo schema della tabella Delta corrisponde perfettamente al target.\")\n",
    "    else:\n",
    "        print(\"\\n[FAIL] ATTENZIONE: Lo schema della tabella Delta NON corrisponde allo schema target!\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERRORE: La tabella Delta non è stata trovata in '{DELTA_QUALITA_ARIA_PATH}'.\")\n",
    "except Exception as e:\n",
    "    print(f\"Si è verificato un errore durante la verifica della tabella Delta: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb17ffbc-a383-4c83-a8cc-dfa869c2536c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
